<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Resume</title>
  <link rel="stylesheet" href="resume.css"> 
</head>
<body>
    <h2 id="kshitij-sharma">Kshitij Sharma</h2>
    <p><strong>Data Analyst | Python &amp; Analytics | Open-Source Library
    (datalabx)</strong></p>
    <p><strong>Location:</strong> Remote<br> <strong>GitHub:</strong>
    https://www.github.com/TheDucky-2/datalabx<br> <strong>LinkedIn:</strong>
    https://www.linkedin.com/in/kshitij-sharma-2054a0376<br>
    <strong>Email:</strong> Ksharma199@protonmail.com<br>
    <strong>Phone</strong>: +91-7983058329</p>
    <h2 id="professional-summary">PROFESSIONAL SUMMARY</h2>
    <ul>
    <li>Python-focused Data Analyst / Associate Data Scientist with strong
    experience designing diagnosis-first data quality and preparation
    workflows for messy, real-world datasets.</li>
    <li>Open-source author and maintainer of <strong>datalabx</strong>, a
    modular Python framework for data diagnostics, cleaning, preprocessing,
    and exploratory analysis at scale.</li>
    <li>Skilled at translating ambiguous business questions and unreliable
    raw data into analysis-ready datasets, enabling accurate insights,
    reproducible workflows, and confident decision-making.</li>
    <li>Seeking roles in Data Analysis, Analytics Engineering-adjacent, or
    Python-driven analytics where <strong>technical rigor, data
    understanding, and stakeholder communication intersect.</strong></li>
    </ul>
    <h2 id="technical-skills">TECHNICAL SKILLS</h2>
    <ul>
    <li><strong>Data Analysis &amp; Quality:</strong> Exploratory Data
    Analysis (EDA), data diagnostics and profiling, data cleaning, missing
    data analysis, data quality validation,business metrics
    interpretation.</li>
    <li><strong>Programming:</strong> Python (Pandas, Polars, NumPy, SciPy),
    Object-Oriented Design, SQL (intermediate), modular library
    architecture.</li>
    <li><strong>Visualization &amp; BI:</strong> Power BI, Matplotlib,
    Seaborn, Plotly, diagnostic Visulizations.</li>
    <li><strong>Data Tooling:</strong> Git &amp; GitHub, Python packaging
    (pyproject.toml), CI/CD (GitHub Actions), Documentation tooling (pdoc),
    TestPyPI, MS-Excel.</li>
    <li><strong>Graph Analytics:</strong> NetworkX, Neo4j (Certified
    Professional).</li>
    <li><strong>Business Strengths</strong>: Customer problem-solving,
    stakeholder communication, workflow improvement, risk mitigation.</li>
    </ul>
    <h2 id="project-experience">PROJECT EXPERIENCE</h2>
    <h3 id="datalabx---open-source-python-data-diagnostics-library">datalabx -
    Open-Source Python Data Diagnostics Library</h3>
    <p><strong>Open-Source Project</strong><br> Python, Pandas, Polars,
    Numpy, Matplotlib<br> <em>(v0.1 Pre-release)</em><br>
    <strong>GitHub</strong>: https://github.com/TheDucky-2/datalabx
    <strong>API Docs</strong>: https://theducky-2.github.io/datalabx/</p>
    <ul>
    <li>Designed and built a modular Python library for diagnosing and
    cleaning highly dirty tabular datasets <strong>(77–90% invalid or
    inconsistent values)</strong>, implementing type-aware diagnostics for
    numerical, text, categorical, and datetime columns with <strong>20+
    regex rules</strong>.<br />
    </li>
    <li>Built a pandas-facing API backed by a Polars engine, efficiently
    processing <strong>5–10M row</strong> datasets and reducing runtime from
    <strong>30+ seconds to ~5–10 seconds</strong> via vectorized
    expressions.<br />
    </li>
    <li>Developed <strong>column-level diagnostics</strong> exposing
    formatting errors, coercion risks, missingness patterns, invalid values,
    and conversion failures to <strong>improve auditability</strong>.<br />
    </li>
    <li>Designed explicit, <strong>user-controlled cleaning
    workflows</strong> to prevent silent coercion and <strong>unintended
    data loss</strong>.<br />
    </li>
    <li>Wrote structured documentation, API references, workflow guides
    while published and packaged <strong>7 alpha/beta releases</strong> to
    TestPyPI using modern Python packaging standards
    <strong>(pyproject.toml)</strong>.</li>
    </ul>
    <h3 id="power-bi-analytics-projects">Power BI &amp; Analytics
    Projects</h3>
    <p><strong>Anti-Money Laundering Analysis - Power BI</strong></p>
    <p><strong>GitHub</strong>:
    https://github.com/TheDucky-2/Anti-Money-Laundering-Analysis</p>
    <ul>
    <li>Built interactive <strong>Power BI dashboards</strong> for
    exploratory and performance analysis.</li>
    <li><strong>Cleaned, transformed</strong>, and
    <strong>validated</strong> datasets prior to visualization using
    Python.</li>
    <li>Identified <strong>trends, correlations, and actionable
    insights</strong> aligned with business-style questions.</li>
    <li>Designed dashboards emphasizing <strong>clarity, usability, and
    decision support</strong>.</li>
    <li>Documented <strong>metrics, assumptions, and findings</strong> to
    ensure reproducibility and transparency.</li>
    </ul>
    <h2 id="professional-experience">PROFESSIONAL EXPERIENCE</h2>
    <p><strong>Author &amp; Maintainer - datalabx (Open-Source)</strong>
    Self-directed | 2025 - Present Python, Pandas, Polars, NumPy, Data
    Diagnostics, API Design, Documentation</p>
    <ul>
    <li>Designed and built a <strong>diagnosis-first data quality and
    preparation framework</strong> for messy real-world tabular datasets,
    emphasizing correctness, transparency, and auditability.</li>
    <li>Architected a modular Python library covering the <strong>full data
    lifecycle</strong>: loading -&gt; diagnosis -&gt; visualization -&gt;
    cleaning -&gt; preprocessing -&gt; statistical analysis.</li>
    <li>Implemented <strong>type-aware diagnostics</strong> for numerical,
    categorical, text, and datetime data, surfacing invalid values,
    formatting inconsistencies, missingness patterns, and coercion
    risks.</li>
    <li>Developed explicit, <strong>user-controlled cleaning
    workflows</strong>, avoiding silent type coercion and unintended data
    loss.</li>
    <li>Built column-level <strong>conversion failure tracking</strong>,
    enabling users to audit which values fail transformations and why.</li>
    <li>Designed a <strong>pandas-friendly public API</strong> backed by a
    <strong>Polars execution engine</strong>, enabling efficient processing
    of datasets with <strong>5–10 million rows</strong>.</li>
    <li>Reduced diagnostic runtime from <strong>30+ seconds to ~ 5-10
    seconds</strong> on large datasets through vectorized expressions and
    backend abstraction.</li>
    <li>Implemented reusable components for <strong>statistical
    summaries</strong>, <strong>distributions</strong>,
    <strong>correlations</strong>, and <strong>outlier
    detection</strong>.</li>
    <li>Created diagnosis-backed visualizations for missingness, categorical
    distributions, and numerical patterns.</li>
    <li>Established documentation standards including <strong>API
    references</strong>, <strong>workflow guides</strong>, and
    <strong>examples</strong> using pdoc.</li>
    <li>Packaged, versioned, and published the library to
    <strong>TestPyPI</strong>, following modern Python packaging standards
    <strong>(pyproject.toml)</strong>.</li>
    <li>Set up <strong>CI automation</strong> with <strong>GitHub
    Actions</strong> to build and deploy documentation to GitHub Pages.</li>
    <li>Maintained the codebase through iterative refactoring, bug fixes,
    and documentation improvements based on usability feedback.</li>
    </ul>
    <p><strong>Senior Customer Experience Specialist — American
    Express</strong><br> 2.5 Years</p>
    <ul>
    <li><p>Investigated complex, high-risk transaction and fraud cases in a
    regulated enterprise environment</p></li>
    <li><p>Analyzed recurring issue patterns and contributed to workflow and
    process improvements</p></li>
    <li><p>Collaborated with compliance, operations, and technical teams on
    escalated investigations</p></li>
    <li><p>Developed strong documentation, analytical reasoning, and
    stakeholder communication skills under time pressure</p></li>
    </ul>
    <p><strong>Customer-Facing &amp; Operations Roles - Various
    Organizations</strong><br> Total Experience: 7+ Years</p>
    <ul>
    <li><p>Worked directly with customers and internal stakeholders across
    multiple roles</p></li>
    <li><p>Handled ambiguous, incomplete, and conflicting information on a
    daily basis</p></li>
    <li><p>Developed strong communication, prioritization, and analytical
    reasoning skills</p></li>
    <li><p>Built resilience and attention to detail in high-volume,
    high-accountability environments</p></li>
    </ul>
    <h2 id="education-certifications">EDUCATION &amp; CERTIFICATIONS</h2>
    <ul>
    <li><p>Neo4j Certified Professional</p></li>
    <li><p>Applied Data Science with Python - University of
    Michigan</p></li>
    <li><p>IBM Data Fundamentals</p></li>
    <li><p>Continuous self-directed learning through <strong>open-source
    development and applied analytics projects</strong></p></li>
    </ul>
    <p><strong>ADDITIONAL INFORMATION</strong></p>
    <ul>
    <li><p>Combines 7+ years of customer-facing experience with technical
    Python and analytics skills, enabling business-aligned
    insights.</p></li>
    <li><p>Strong focus on data correctness, transparency, and
    reproducibility.</p></li>
    <li><p>Comfortable bridging <strong>business and technical
    stakeholders</strong>.</p></li>
    <li><p>Open-source contributor mindset with a focus on <strong>practical
    solutions, learning, and mentorship</strong>.</p></li>
    </ul>
</body>
</html>